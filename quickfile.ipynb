{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aug 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'data/TUM_RGBD/rgbd_dataset_freiburg1_desk/language_features_dim3/1305031452.791720_f.npy'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.load(path).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jul 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means3D\n",
      "rgb_colors\n",
      "pointwise_le\n",
      "unnorm_rotations\n",
      "logit_opacities\n",
      "log_scales\n",
      "cam_unnorm_rots\n",
      "cam_trans\n",
      "timestep\n",
      "intrinsics\n",
      "w2c\n",
      "org_width\n",
      "org_height\n",
      "gt_w2c_all_frames\n",
      "keyframe_time_indices\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "load_path = '/mnt/c2d9b23a-b03e-4fdb-82ad-59f039ec9e3e/intern/King_Hang/OFFLINE-samslam_2/experiments/Replica/room0_0/params.npz'\n",
    "data = np.load(load_path)\n",
    "\n",
    "for key in data.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208295, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "query_tensor = torch.Tensor([[0.7379534, 0.6642408, -0.1192008]])\n",
    "\n",
    "data['pointwise_le'].shape # (208205,9)\n",
    "le_s = data['pointwise_le'][:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1182208/292529175.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  query_tensor = torch.tensor(query_tensor, dtype=torch.float32)\n",
      "/tmp/ipykernel_1182208/292529175.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  le_s = torch.tensor(le_s, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "def get_cosine_similarity(query_tensor, le_s):\n",
    "\n",
    "    # settings\n",
    "    cos_threshold = 0.1\n",
    "\n",
    "    # Convert numpy arrays to tensors if needed\n",
    "    if isinstance(query_tensor, np.ndarray):\n",
    "        query_tensor = torch.from_numpy(query_tensor)\n",
    "    if isinstance(le_s, np.ndarray):\n",
    "        le_s = torch.from_numpy(le_s)\n",
    "    \n",
    "    query_tensor = torch.tensor(query_tensor, dtype=torch.float32)\n",
    "    le_s = torch.tensor(le_s, dtype=torch.float32)\n",
    "    \n",
    "    # check dimensions\n",
    "    if query_tensor.dim() != 2 or le_s.dim() != 2:\n",
    "        raise ValueError(\"Both query_tensor and le_s should be 2D tensors.\")\n",
    "    if query_tensor.size(1) != le_s.size(1):\n",
    "        raise ValueError(\"The second dimension of query_tensor and le_s must be the same.\")\n",
    "\n",
    "    norm_query_tensor = query_tensor / query_tensor.norm(dim=1, keepdim=True)\n",
    "    norm_le_s = le_s / le_s.norm(dim=1, keepdim=True)\n",
    "    \n",
    "    cosine_similarities = torch.mm(norm_query_tensor, norm_le_s.t())\n",
    "    indices = (cosine_similarities.squeeze(0) > cos_threshold).nonzero(as_tuple=True)[0]\n",
    "    \n",
    "    return cosine_similarities, indices\n",
    "\n",
    "le_s = data['pointwise_le'][:,:3]\n",
    "cosine_similarities, indices = get_cosine_similarity(query_tensor, le_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0874785 , -0.09367711, -1.1776744 ],\n",
       "       [ 0.5383674 , -0.24182074, -0.86271596],\n",
       "       [ 0.5749505 , -0.19785348, -0.8421425 ],\n",
       "       ...,\n",
       "       [ 0.58902586, -0.39352894, -0.7153767 ],\n",
       "       [ 0.5780935 , -0.39636886, -0.7157943 ],\n",
       "       [ 0.53266346, -0.44069973, -0.7087772 ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_s[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from natsort import natsorted\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"./data/Replica/room0\"\n",
    "f_path = os.path.join(input_folder, 'language_features_dim3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_paths = natsorted(glob.glob(f\"{input_folder}/language_features_dim3/*_s.npy\"))\n",
    "f_paths = natsorted(glob.glob(f\"{input_folder}/language_features_dim3/*_f.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([150, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_path = f_paths[0]\n",
    "f1= torch.from_numpy(np.load(f_path))\n",
    "f1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 680, 1200])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_path = s_paths[0]\n",
    "s1= torch.from_numpy(np.load(s_path))\n",
    "s1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 816000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = seg != -1 # >> change to 0 later\n",
    "\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i : \n",
      "1\n",
      "i : \n",
      "2\n",
      "i : \n",
      "3\n"
     ]
    }
   ],
   "source": [
    "seg_map = s1\n",
    "feature_map = f1\n",
    "\n",
    "height, width = 680, 1200\n",
    "le_dim = 3 #>> CLIP = 512, scenewise = 3\n",
    "n_seg_lvls = 3\n",
    "\n",
    "y, x = torch.meshgrid(torch.arange(0, height), torch.arange(0, width))\n",
    "x = x.reshape(-1, 1)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "seg = seg_map[:, y, x].squeeze(-1).long()\n",
    "mask = seg != -1 # >> change to 0 later\n",
    "\n",
    "all_lvl_feats = torch.zeros((n_seg_lvls, le_dim, height, width)) \n",
    "all_lvl_masks = torch.zeros((n_seg_lvls, 1, height, width))\n",
    "\n",
    "for i in range(1, 4):  # only use s, m, l\n",
    "    print('i : ')\n",
    "    print(i)\n",
    "    point_feature1 = feature_map[seg[i:i+1]].squeeze(0)\n",
    "    point_feature = point_feature1.reshape(height, width, -1).permute(2, 0, 1)\n",
    "    all_lvl_feats[i-1] = point_feature\n",
    "\n",
    "    # get mask\n",
    "    lvl_mask = mask[i:i+1].reshape(1, height, width)\n",
    "    all_lvl_masks[i-1] = lvl_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 680, 1200])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_map.shape\n",
    "seg_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['means3D', 'rgb_colors', 'pointwise_le', 'unnorm_rotations', 'logit_opacities', 'log_scales', 'cam_unnorm_rots', 'cam_trans']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.7695265 , -0.15192293, -0.6202809 , -0.46570873, -0.07955976,\n",
       "        -0.8813544 , -0.6167774 , -0.07923762, -0.7305264 ],\n",
       "       [-0.7695265 , -0.15192293, -0.6202809 , -0.46570873, -0.07955976,\n",
       "        -0.8813544 , -0.6659762 , -0.02166895, -0.69057965],\n",
       "       [-0.7695265 , -0.15192293, -0.6202809 , -0.46570873, -0.07955976,\n",
       "        -0.8813544 , -0.65042406, -0.08929549, -0.69569665],\n",
       "       [-0.7695265 , -0.15192293, -0.6202809 , -0.46570873, -0.07955976,\n",
       "        -0.8813544 , -0.6451719 , -0.11420973, -0.6805587 ],\n",
       "       [-0.7695265 , -0.15192293, -0.6202809 , -0.46570873, -0.07955976,\n",
       "        -0.8813544 , -0.6837491 , -0.16649857, -0.7151868 ],\n",
       "       [-0.7695265 , -0.15192293, -0.6202809 , -0.46570873, -0.07955976,\n",
       "        -0.8813544 , -0.6958984 , -0.15972506, -0.684766  ],\n",
       "       [-0.7695265 , -0.15192293, -0.6202809 , -0.46570873, -0.07955976,\n",
       "        -0.8813544 , -0.70884556, -0.10204678, -0.69775265],\n",
       "       [-0.7695265 , -0.15192293, -0.6202809 , -0.46570873, -0.07955976,\n",
       "        -0.8813544 , -0.7082661 , -0.07994196, -0.71150434],\n",
       "       [-0.7695265 , -0.15192293, -0.6202809 , -0.46570873, -0.07955976,\n",
       "        -0.8813544 , -0.7206582 , -0.10813577, -0.66906947],\n",
       "       [-0.7695265 , -0.15192293, -0.6202809 , -0.46570873, -0.07955976,\n",
       "        -0.8813544 , -0.754102  , -0.08174768, -0.68600094]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "path = '/mnt/c2d9b23a-b03e-4fdb-82ad-59f039ec9e3e/intern/King_Hang/OFFLINE-samslam/experiments/Replica/room0_0/params10.npz'\n",
    "obj = np.load(path)\n",
    "\n",
    "print(obj.files)\n",
    "\n",
    "\n",
    "obj['pointwise_le'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jul 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of the dump file:\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load the dump file\n",
    "dump_file = \"buggy.dump\"\n",
    "try:\n",
    "    data_0 = torch.load(dump_file)\n",
    "    print(\"Contents of the dump file:\")\n",
    "    # print(data)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading the dump file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raster_settings.bg\n",
      "torch.Size([3])\n",
      "\n",
      "\n",
      "means3D\n",
      "torch.Size([950337, 3])\n",
      "\n",
      "\n",
      "colors_precomp\n",
      "torch.Size([950337, 3])\n",
      "\n",
      "\n",
      "language_feature_precomp\n",
      "torch.Size([1])\n",
      "\n",
      "\n",
      "opacities\n",
      "torch.Size([950337, 1])\n",
      "\n",
      "\n",
      "scales\n",
      "torch.Size([950337, 3])\n",
      "\n",
      "\n",
      "rotations\n",
      "torch.Size([950337, 4])\n",
      "\n",
      "\n",
      "raster_settings.scale_modifier\n",
      "1.0\n",
      "\n",
      "\n",
      "cov3Ds_precomp\n",
      "torch.Size([0])\n",
      "\n",
      "\n",
      "raster_settings.viewmatrix\n",
      "torch.Size([1, 4, 4])\n",
      "\n",
      "\n",
      "raster_settings.projmatrix\n",
      "torch.Size([1, 4, 4])\n",
      "\n",
      "\n",
      "raster_settings.tanfovx\n",
      "1.0\n",
      "\n",
      "\n",
      "raster_settings.tanfovy\n",
      "0.5666666666666667\n",
      "\n",
      "\n",
      "raster_settings.image_height\n",
      "680\n",
      "\n",
      "\n",
      "raster_settings.image_width\n",
      "1200\n",
      "\n",
      "\n",
      "sh\n",
      "torch.Size([0])\n",
      "\n",
      "\n",
      "raster_settings.sh_degree\n",
      "0\n",
      "\n",
      "\n",
      "raster_settings.campos\n",
      "torch.Size([3])\n",
      "\n",
      "\n",
      "raster_settings.prefiltered\n",
      "False\n",
      "\n",
      "\n",
      "raster_settings.debug\n",
      "True\n",
      "\n",
      "\n",
      "raster_settings.include_feature\n",
      "True\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args_list = [\n",
    "    \"raster_settings.bg\",\n",
    "    \"means3D\",\n",
    "    \"colors_precomp\",\n",
    "    \"language_feature_precomp\",\n",
    "    \"opacities\",\n",
    "    \"scales\",\n",
    "    \"rotations\",\n",
    "    \"raster_settings.scale_modifier\",\n",
    "    \"cov3Ds_precomp\",\n",
    "    \"raster_settings.viewmatrix\",\n",
    "    \"raster_settings.projmatrix\",\n",
    "    \"raster_settings.tanfovx\",\n",
    "    \"raster_settings.tanfovy\",\n",
    "    \"raster_settings.image_height\",\n",
    "    \"raster_settings.image_width\",\n",
    "    \"sh\",\n",
    "    \"raster_settings.sh_degree\",\n",
    "    \"raster_settings.campos\",\n",
    "    \"raster_settings.prefiltered\",\n",
    "    \"raster_settings.debug\",\n",
    "    \"raster_settings.include_feature\"\n",
    "]\n",
    "\n",
    "for d, arg in zip(data_0, args_list):\n",
    "    if isinstance(d, torch.Tensor):\n",
    "        print(arg)\n",
    "        print(d.shape)\n",
    "    else:\n",
    "        print(arg)\n",
    "        print(d)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how does a normal looking file look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of the dump file:\n",
      "(tensor([0., 0., 0.]), tensor([[-1.2046, -0.6822,  1.2056],\n",
      "        [-1.2041, -0.6830,  1.2071],\n",
      "        [-1.2035, -0.6838,  1.2085],\n",
      "        ...,\n",
      "        [ 1.6546,  0.9402,  1.6616],\n",
      "        [ 1.6574,  0.9402,  1.6616],\n",
      "        [ 1.6605,  0.9403,  1.6619]]), tensor([[1.2056, 1.0000, 1.4535],\n",
      "        [1.2071, 1.0000, 1.4572],\n",
      "        [1.2085, 1.0000, 1.4605],\n",
      "        ...,\n",
      "        [1.6616, 1.0000, 2.7608],\n",
      "        [1.6616, 1.0000, 2.7608],\n",
      "        [1.6619, 1.0000, 2.7618]]), tensor([0.]), tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        ...,\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]]), tensor([[0.0020, 0.0020, 0.0020],\n",
      "        [0.0020, 0.0020, 0.0020],\n",
      "        [0.0020, 0.0020, 0.0020],\n",
      "        ...,\n",
      "        [0.0028, 0.0028, 0.0028],\n",
      "        [0.0028, 0.0028, 0.0028],\n",
      "        [0.0028, 0.0028, 0.0028]]), tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]]), 1.0, tensor([]), tensor([[[ 1.0000e+00, -1.4901e-08,  5.1038e-17,  0.0000e+00],\n",
      "         [-1.7725e-09,  1.0000e+00, -9.0462e-26,  0.0000e+00],\n",
      "         [ 3.6851e-08, -2.9802e-08,  1.0000e+00,  0.0000e+00],\n",
      "         [ 1.1921e-07, -2.3842e-07,  6.0842e-24,  1.0000e+00]]]), tensor([[[ 1.0000e+00, -2.6296e-08,  5.1043e-17,  5.1038e-17],\n",
      "         [-1.7725e-09,  1.7647e+00, -9.0471e-26, -9.0462e-26],\n",
      "         [-8.3330e-04, -1.4706e-03,  1.0001e+00,  1.0000e+00],\n",
      "         [ 1.1921e-07, -4.2074e-07, -1.0001e-02,  6.0842e-24]]]), 1.0, 0.5666666666666667, 680, 1200, tensor([]), 0, tensor([-1.1921e-07,  2.3842e-07,  1.3696e-40]), False, True, True)\n"
     ]
    }
   ],
   "source": [
    "dump_file = \"snapshot_fw.dump\"\n",
    "try:\n",
    "    data = torch.load(dump_file)\n",
    "    print(\"Contents of the dump file:\")\n",
    "    print(data)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading the dump file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raster_settings.bg\n",
      "torch.Size([3])\n",
      "\n",
      "\n",
      "means3D\n",
      "torch.Size([815998, 3])\n",
      "\n",
      "\n",
      "colors_precomp\n",
      "torch.Size([815998, 3])\n",
      "\n",
      "\n",
      "language_feature_precomp\n",
      "torch.Size([1])\n",
      "\n",
      "\n",
      "opacities\n",
      "torch.Size([815998, 1])\n",
      "\n",
      "\n",
      "scales\n",
      "torch.Size([815998, 3])\n",
      "\n",
      "\n",
      "rotations\n",
      "torch.Size([815998, 4])\n",
      "\n",
      "\n",
      "raster_settings.scale_modifier\n",
      "1.0\n",
      "\n",
      "\n",
      "cov3Ds_precomp\n",
      "torch.Size([0])\n",
      "\n",
      "\n",
      "raster_settings.viewmatrix\n",
      "torch.Size([1, 4, 4])\n",
      "\n",
      "\n",
      "raster_settings.projmatrix\n",
      "torch.Size([1, 4, 4])\n",
      "\n",
      "\n",
      "raster_settings.tanfovx\n",
      "1.0\n",
      "\n",
      "\n",
      "raster_settings.tanfovy\n",
      "0.5666666666666667\n",
      "\n",
      "\n",
      "raster_settings.image_height\n",
      "680\n",
      "\n",
      "\n",
      "raster_settings.image_width\n",
      "1200\n",
      "\n",
      "\n",
      "sh\n",
      "torch.Size([0])\n",
      "\n",
      "\n",
      "raster_settings.sh_degree\n",
      "0\n",
      "\n",
      "\n",
      "raster_settings.campos\n",
      "torch.Size([3])\n",
      "\n",
      "\n",
      "raster_settings.prefiltered\n",
      "False\n",
      "\n",
      "\n",
      "raster_settings.debug\n",
      "True\n",
      "\n",
      "\n",
      "raster_settings.include_feature\n",
      "True\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args_list = [\n",
    "    \"raster_settings.bg\",\n",
    "    \"means3D\",\n",
    "    \"colors_precomp\",\n",
    "    \"language_feature_precomp\",\n",
    "    \"opacities\",\n",
    "    \"scales\",\n",
    "    \"rotations\",\n",
    "    \"raster_settings.scale_modifier\",\n",
    "    \"cov3Ds_precomp\",\n",
    "    \"raster_settings.viewmatrix\",\n",
    "    \"raster_settings.projmatrix\",\n",
    "    \"raster_settings.tanfovx\",\n",
    "    \"raster_settings.tanfovy\",\n",
    "    \"raster_settings.image_height\",\n",
    "    \"raster_settings.image_width\",\n",
    "    \"sh\",\n",
    "    \"raster_settings.sh_degree\",\n",
    "    \"raster_settings.campos\",\n",
    "    \"raster_settings.prefiltered\",\n",
    "    \"raster_settings.debug\",\n",
    "    \"raster_settings.include_feature\"\n",
    "]\n",
    "\n",
    "for d, arg in zip(data, args_list):\n",
    "    if isinstance(d, torch.Tensor):\n",
    "        print(arg)\n",
    "        print(d.shape)\n",
    "    else:\n",
    "        print(arg)\n",
    "        print(d)\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splatam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
